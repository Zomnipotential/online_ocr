\documentclass[12pt,a4paper]{article}

% APA style
\usepackage{courier} % For the Courier font
\usepackage[margin=1in]{geometry} % For 1-inch margins
\usepackage{url} % Load the url package

% For change of font color inline
\usepackage{xcolor}

% Add package for images
\usepackage{graphicx}

% For sub figures
\usepackage{subcaption}

\usepackage[utf8]{inputenc}
\usepackage[swedish]{babel}
\usepackage{tocloft}

% Add package for bibliography
\usepackage[authoryear]{natbib}
\setcitestyle{round}

% Customize the table of contents appearance
\renewcommand{\cfttoctitlefont}{\Huge\bfseries} % Title font
\renewcommand{\cftsecfont}{\bfseries} % Section font
\renewcommand{\cftsecpagefont}{\bfseries} % Page number font
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} % Leader dots
\renewcommand{\cftsecaftersnum}{.} % Add a dot after section numbers
\setlength{\cftbeforesecskip}{0.5em} % Space before section entries

% Define the title page
\title{\Huge{JÄMFÖRELSE AV\\MASKININLÄRNINGSMODELLER\\
FÖR HANDSKRIVEN SIFFERKLASSIFICERING}}
\author{Matthew H. Motallebipour}
\date{\today}

% Add the author's affiliation
\newcommand{\institute}[1]{%
  \begin{center}
    \large{#1}
  \end{center}
}

\begin{document}

\maketitle
\institute{Yrkeshögskolan EC Utbildning}

\newpage

% Add the abstract
\begin{abstract}
    \noindent
    \textbf{Abstract:} The present report elaborates on a comparison between three different machine learning models for classification of handwritten digits: Support Vector Machines (SVM), Random Forests (RF), and Extreme Gradient Boosting (XGBoost). The models are compared and ranked based on accuracy. In the second part of the report, an ensemble learning model is also presented, which is used to create a Python application in the Streamlit framework that classifies uploaded images with an accuracy of about 98\%.
  \end{abstract}
  
\newpage

  % Add the abstract
\begin{abstract}
    \noindent
    \textbf{Abstract:} Föreliggande rapport presenterar en jämförelse mellan tre olika maskininlärningsmodeller för klassificering av handskrivna siffror: Support Vector Machines, Random Forest, och Extreme Gradient Boosting. Modellerna jämförs och rangordnas med avseende på noggrannhet. I den andra delen av rapporten presenteras också en ensemble inlärning modell som används för att framställa en Python-applikation i ramverket Streamlit som via en server klassificerar uppladdade bilder med en noggrannhet på cirka 98\%.
  \end{abstract}

\newpage

% Add acknowledgements
\section*{Acknowledgements}
I would like to thank my supervisor, Mr.~Antonio Prgomet, for his outstanding teaching and his guidance throughout the whole project. I would also like to thank my dear friend, Mr.~Robert Shaw for his invaluable contributions; a peer through whose journalistic scrutiny I was able to realize the shortcomings in my work and improve upon them. Finally, thank you to all my fellow students that are always there for a good discussion throughout all courses.

\newpage

% Add a list of abbreviations
\section*{Förkortningar}
\begin{tabular}{ll}
    SVM & Support Vector Machines \\
    RF & Random Forest \\
    XGBoost & Extreme Gradient Boosting \\
    ML & Machine Learning \\
    DL & Deep Learning \\
    CNN & Convolutional Neural Network \\
    GUI & Graphical User Interface \\
    API & Application Programming Interface \\
    IDE & Integrated Development Environment \\
    TPE & Tree-structured Parzen Estimator \\

\end{tabular}

\newpage

% Add a list of figures
\listoffigures

\newpage

% Add a list of tables
\listoftables

\newpage

% Add the table of contents
\newpage
\tableofcontents

%\section{Inledning}
%\subsection{Syfte}
%\subsection{Frågeställning}
%\subsection{Textens disposition}
%\section{Teori}
%\section{Metod}
%\subsection{Steg 1}
%\subsection{Steg 2}
%\section{Resultat}
%\section{Diskussion}
%\section{Slutsats}
%\subsection{Framtida arbete}
%\section{Appendix}
%\section{Källförteckning}

\newpage

% Add Inledning
\section{Inledning}

För bara några år tillbaka i tiden kunde man inte föreställa sig att algoritmer inom det nytillkomna, heta området maskininlärning skulle på så kort tid revolutionera takniken och människors syn på framtiden. Speciellt efter introduktionen av djupinlärning (DL) och faltningsneuronnät (CNN) har maskininlärning (ML) blivit så populär att skolor och universitet runtom Sverige har börjat erbjuda kurser inom området för lärare för att kunna bemöta den ökande efterfrågan på ML-kunnandet (Skolverket, 2020). Därför är det ytterst väsentligt att vi som studenter och forskare inom området maskininlärning förstår de olika modellerna och deras styrkor och svagheter.

\subsection{Syfte}

Denna rapport ämnar behandla tre olika ML-modeller, nämligen Support Vector Machines (SVM), Random Forest (RF), och Extreme Gradient Boosting (XGBoost). Syftet är att besvara frågan om dessa modeller i allmännhet kan klassificera handskrivna siffror med en acceptabel noggrannhet. I synnerhet kommer vi att jämföra skillnaden mellan dessa tre och se vilken som fungerar bäst. 

\subsection{Frågeställning}

Den specifika frågan är vilken av de tre modellerna SVM, RF och XGBoost är det bästa alternativet för klassificering av handskrivna siffror.

\subsection{Textens disposition}

Först kommer vi att titta på våra tidigarenämnda modeller och vad de är. Därefter presenteras det lite olika metoder för att förbehandla och senare klassificera bilderna som används som träningsdata. I resultatdelen kommer vi att presentera hur våra modeller klarat av utmaningen. I diskussionsdelen kommer vi att jämföra och rangordna modellerna och i den sista delen kommer vi presentera vår slutsats och förslag på framtida arbeten för att förbättra resultaten.

\section{Teori}

För klassificering av data i olika former såsom bild, text eller ljud finns det många olika alternativ inom maskininlärning. Dessa alternativ kallas modeller varav de mest kända är Logsitic Regression, Decision Trees, Random Forest, Gradient Boosting Machines, Support Vector Machines, k-Nearest Neighbors, Naive Bayes, Neural Networks, Linear Discriminant Analysis, Adaboost, Bootstrap Aggregating (Bagging), extra trees~\citep{Geron}, Quadratic Discriminant Analysis~\citep{Bishop}, Gaussian Process Classifiers~\citep{Gibbs}, Passive Aggressive Classifiers~\citep{Crammer} och många fler.

Vi valde att begränsa oss till en jämförelse mellan tre av dessa modeller: Support Vector Machines, Random Forest och Extreme Gradient Boosting. Dessa modeller är kända för att vara effektiva och används ofta i praktiken.

\subsection{Support Vector Machines (SVM)}

SVM är en linjär klassificerare som försöker hitta den bredaste marginalen som kan separera två klasser. Den används både för klassificering och regression men används mest för klassificering. SVM är en övervakad algoritm baserad på Vapnik-Chervonenkis teori, se Figur~\ref{fig:svm} från~\cite{Geron}. Om klasserna inte är linjärt separerbara kan vi använda icke-linjär SVM, t ex polynomial kernel eller radial kernel; se Figur~\ref{fig:nonlinearsvm}.

% Add a tabular for two images on the same row
\begin{figure}[t]
  \centering
  \begin{tabular}{cc}
      \includegraphics[width=0.4\textwidth]{report_svm.png} & 
      \includegraphics[width=0.4\textwidth]{report_svmoutliers.png} \\
      (a) \& (b) \\
  \end{tabular}
  \caption{\footnotesize{Support Vector Machines: [G\'eron] (a) Linjär separerbar data. De två streckade linerna visar marginalen medan den hela linjen är beslutsgränsen (b) Icke-linjär separerbar data.}}\label{fig:svm}
  % Remove the extra space
\end{figure}

% Add a figure for report_nonlinearsvm.png
\begin{figure}[b]
  \centering
  \includegraphics[width=0.4\textwidth]{report_nonlinearsvm.png}
  \caption{\footnotesize{Vänster: SVM med polynomkärna av grad 3 applicerad på icke-linjär separerbar data. Höger: SVM radiell kärna applicerad på samma data. Båda visar framgångsrik klassificering. Mer om detta kan läsas i James et al. (2013), pages 353--358.}}\label{fig:nonlinearsvm}
\end{figure}

Random Forest är en ensemble inlärningsmodell som består av flera beslutsträd. Varje träd i skogen är en enkel klassificerare som bygger på slumpmässigt valda egenskaper som, rent praktiskt, är kolumnerna i befinlig data-tabell. RF är också en mycket effektiv algoritm som tvärtemot SVM är robust mot outliers. Det är därför som vi har inkluderat den i implementeringen av vår sifferklassificerare. RF är med andra ord en aggregerad modell vars utfall är baserad på en majoritsröstning av alla träd.

Leo Breiman, who is also known for introducing Bootstrap Aggregating (Bagging) \citep{Geron}, is the creator of this well-known model, along with Adele Cutler~\citep{Izenman}.

\subsection{Extreme Gradient Boosting (XGBoost)}

XGBoost är inte från samma katalog som de ovannämnda modellerna, utan den har en egen katalog i Python. XGBoost är en optimerad version av Gradient Boosting Machines som är en ensemble inlärningsmodell som liksom RF också består av flera beslutsträd. Skillnaden är att denna innehåller träd som byggs på varandra i en sekventiell ordning och inte parallellt som i RF. Varje träd i XGBoost bygger på felet, de så kallade residualer som är skillanderna mellan de predikterade och de reela värdena, från det föregående trädet. Denna modell använder också early stopping för att undvika överanpassning till data och därmed minska bias~\citep{Geron}. Early stopping innebhär helt enkelt att det enskilda trädet inte byggs på när residualen inte längre minskar avsevärt. XGBoost har visat sig vara snabbare än sin föregångare, i scikit-learn implementaterade versionen av gradient boosting, och används därför ofta inom ML-tävlingar~\citep{Guido}.

Vad vi vet är att beslutsträd i allmänhet har en inneboende varaians, eftersom de har en tendens att anpassa sig till träningsdata mycket väl, samt att den minsta förändringen i hyperparameterarna kan leda till att skapa helt olika modeller~\citep{Geron}. RF och XGBoost är mycket effektiva modeller som båda motverkar den egenskapen~\citep{Geron}. Därför är det intressant att jämföra dessa två med SVM för att se vilken som är bäst för klassificering av handskrivna siffror.

% Add a tabular for two images on the same row
\begin{figure}[t]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.4\textwidth]{report_rf.png} & 
        \includegraphics[width=0.4\textwidth]{report_gradientboost.png} \\
        (a) & (b) \\
    \end{tabular}
    \caption{\footnotesize{Random Forest~\citep{IBM} (a) och Gradient Boosting~\citep{Geron} (b)}}\label{fig:rf_xgboost}
\end{figure}

\subsection{PCA}

Principalkomponentanalys (PCA) är enkelt sagt den matematiska methoden som används för att eliminera överflödig information i form av dimensionen på data utan att minska variationen av informationen avsevärt. Det innebär rent praktiskt att man transformerar det aktuella koordinatsystemet till ett nytt sådant där de nya ortonormala komponenterna, eller variablerna, rangordnas efter hur stor variation i datan de representerar.

PCA används ofta för att minska dimensionen på data och för att visualisera data i en lägre dimensionell rum~\citep{Jolliffe}. Enligt~\cite{Jolliffe} var PCA introducerad av två oberoende personer, Pearson i 1901 och Hotelling i 1933, baserad på Beltramis forskning i 1873 and Jordans i 1874 kring singulärvärdesuppdelning, som i korta ordalag består av en rotation följd av en omskalning och en till rotation~\citep{Wikipedia}.

En viktig tumregel är att man gör PCA sist av alla förbehandlingar, eftersom PCA förändrar data och förhållandena mellan features och gör det därför svårt att tolka data och därmed även omöjliggör andra förbehandlingar som normalisering och standardisering som råkar användas efter just PCA~\citep{Datacamp}.

\subsection{Stratifierad k-faldig korsvalidering}

Stratifierad k-faldig sampling är en metod som används för att dela upp träningsdata i $k$ separata grupper, där varje grupp kallas för en \emph{fold}. Den genererande algoritmen ser till att varje \emph{fold} representerar en lika stor andel av varje klass som finns inom träningsmängden. På det sättet undviker man att vissa klasser inte används i träningen alls. Problemet med att inte ha med alla klasser vid träningstillfället är att den genererade modellen inte kan generalisera såsom det är tänkt. Ett mycket bra exempel på varför stratifierad k-faldig korsvalidering är att föredra före en vanlig sådan kan man läsa på sidan 257 i~\cite{Muller}.

\subsection{Optuna}

Optuna är en ramverk för hyperparameteroptimerings som använder sig av en teknik som kallas för Tree-structured Parzen Estimator (TPE) för att optimera hyperparametrar. TPE i sin tur bygger på Bayesiansk optimering. Optuna är byggd av Takuya Akiba och hans kollegor på Preferred Networks.~\citep{Akiba}.

\subsection{Streamlit}

Streamlit är en ramverk avsedd att hjälpa vid utveckling av webb-applikationer i Python. Applikationen kan både ta emot data från användaren och presentera färdiga, resultat och interaktiva grafer på webben \citep{Richards}. Streamlit installeras enkelt genom den sedvanliga instruktionen \emph{pip} (Preferred Installer Program) och kan köras på den lokala home-servern så gott som på en vanlig webbserver.

Streamlit grundades av Adrien Treuille, Amanda Kelly och Thiago Teixeira \citep{TechCrunch}.

\section{Metod}

För att jämföra de tre modellerna SVM, RF och XGBoost använde vi oss av Python-biblioteken Scikit-learn och XGBoost. All kod implementerades i Jupyter Notebook, bäddad in i VSCode, och på en Mac dator med 1.4 GHz Quad-Core Intel Core i5, 8 GB 2133 MHz LPDDR3, och Intel Iris Plus Graphics 645 1536 MB. Nu ska vi titta närmare på vilka steg vi tog för att komma till mål.

\subsection{Undersökning}

Det första man brukar göra i alla projekt inom ML och data science är att titta på data och se hur den ser ut, vilka egenskaper den har samt vad som kan vara av värde att notera och använda.

Vår givna data bestod av MNIST-datasetet som innehåller bilder på 70 000 handskrivna siffror i storleken 28x28 pixlar. Pixlarna är i gråskala med värden från 0 till 255, som för bättre prestanda standardiserades till att anta värden mellan 0 ch 1\footnote{\footnotesize{Var uppmärksam här på att divisionen med 255 inte är skalning utan standardisering av data. Att skala innebär att subtrahera medelvärdet och dividera resultatet med standardavvikelsen, vilket omvandlar datavärdena till att få medelvärdet $0$ och standardavvikelsen $1$. Det är viktigt för vissa algoritmer som SVM, som är känsliga mot alltför stora värdeförändringar i data, att man normaliserar värdena. I föreliggande problem är detta dock inte nödvändigt, eftersom värdena redan ligger mellan $0$ och $1$.}}. Vi delade upp bilderna i 60 000 träningsbilder och 10 000 testbilder. Dessa laddades in i programmet genom

\subsection{Datarensning}

Därefter försöker man rensa data från information som inte är användbar, eller inte är komplett. I det andra fallet, och om man redan har tillräckligt många datapunkter, eliminerar man de datapunkter som inte är kompletta, dvs att de rader där en eller flera kolumner saknar värden. Alternativet är att man försöker med olika metoder ''gissa'' eller resonera sig fram till vad de saknade värdena kan vara och fyller i det som saknas.

I vårt MNIST dataset fanns det av ganska naturliga skäl inga saknade datapunkter, dvs det fanns inga bilder där de hade värden utanför intervallet $0$ och $255$. Däremot fanns det en misstanke om att en eller flera rader och kolumner, som ligger närmast kanterna på alla bilder, kunde med fördel separeras för att minska antalet punkter som behövde behandlas under träningen. Detta visade sig inte stämma, eftersom eliminering av tre pixlar från alla fyra kanter inte ledde till en  avsevärd förbättring av noggrannheten. Detta kommer att visas och diskuteras på sin plats.

\subsection{Förbehandling}

Till sist organiserar man data så att man kan förbereda den för att utvinna största möjliga information i de efterföljande stegen. När man väl har komplett och rensad data kan man fortsätta med att applicera olika metoder för att minska tid- och minneskostnaden vid träningstillfället, som brukar vara den mest resurskrävande delen vad gäller just tid och minne.

Eftersom vår data redan är i gråskala behövs ingen analys av färger. Däremot kan det vara värt att titta på hur mycket av ytan på varje bild som tas upp av siffrorna. För detta superpositionerade vi alla bilderna, dvs att motsvarande pixelvärdena från alla bilder lades ihop och delades med antalet bilder, alltså att medelvärdet av pixlarna beräknades. Vi tittade på den del av bilderna där det inte förekom några icke-vita pixlar. Det visade sig att siffrorna tar upp en relativt liten del av bilden, vilket kan vara en anledning till att modellerna inte presterade bättre än de gjorde.

Det finns flera olika metoder utav vilka vi använde PCA för den smidighet men samtidigt kapacitet den presenterar.

\subsection{Experiment}

Vi gjorde våra experiment med betydligt färre data, dvs 18 000 träningsbilder, som delades upp i tre lika stora delar. Detta för att spara tid vid många iterationer och test av olika modeller och metoder. På detta sättet tog varje modell högst 10 minuter per iteration. 

\subsection{Val av modell(er)}

Nästa steg blir att använda en eller flera maskininlärningsmodeller för att memorera den underliggande strukturen i data och bygga en färdig motor som kan generalisera och, förhoppningsvis, med god sannolikhet klassificera eller förutse värden för bilder som matas in.

Här använde vi oss av de tre modeller som presenterades redan i teoridelen. Dessa ansåg vi vara de bästa och samtidigt snabbaste man kunde använda. 

\begin{table}[t]
	\footnotesize
  \begin{verbatim}
	from keras.datasets import mnist
    	(X_train, y_train), (X_test, y_test) = mnist.load_data()
  \end{verbatim}
  \caption{\footnotesize{Kod för att ladda in data från MNIST-datasetet}}
\end{table}

\section{Resultat}

Resultatet av körning av de tre utvalda modellerna är sammanfattat i tabellen ovan, Tabell~\ref{comparison table}. Som vi påpekade tidigare användes endast 18 000 bilder vid varje körning för att minska tiden för varje iteration. Tabellen visar att roterade bilder tar upp mer tid än de andra bildformaterna att klassificera, XGBoost är den snabbaste modellen, speciellt vid klassificering av testdata och SVM är den effektivaste när det gäller noggrannhet. Rent allmänt ser vi ingen större skillnad i noggrannhet vid klassificering av data som är trunkerad, roterad eller både trunkerad och roterad. En aneldning till att man kanske sparar lite tid på att trunkera bilderna men att noggrannheten ändå inte påverkas avsevärt kan vara att det ändå försvinner en del pixlar i bilderna som kan vara av värde för vissa bilder. Detta kräver tester med fler bilder och fler iterationer för att kunna avgöra.

\begin{table}[b]
	\centering
	\footnotesize
	\caption{\footnotesize{Tider är räknade i sekunder och högsta och minsta värdet på varje rad är markerad med grön, respektive röd}}\label{comparison table}\vspace{6pt}
	\begin{tabular}{lll | llll}
      \hline 
			&		&		Bildformat $\rightarrow$	& Normal				& Trunkerad			& Roterad				& Trunkerad			\\
		 	&		& 			&					&					&					& och roterad			\\
      \hline 
	SVM 	&		& 			&					&					&					&					\\
			& Träning	& Tid			& \textcolor{blue}{132.4}	& 155.9				& \textcolor{red}{180}	& 155.2				\\
			&		& Noggrannhet	& 97.75\%				& 97.74\%				& 97.77\%				& 97.77\%				\\
			& Test	& Tid			& \textcolor{blue}{40.9}	& 51.6				& \textcolor{red}{55}		& 52.7				\\
			&		& Noggrannhet	& 97.74\%				& 97.70\%				& 97.71\%				& 97.72				\\
	RF 		&		& 			&					&					&					&					\\
			& Träning	& Tid			& 172.6				& \textcolor{blue}{170.6}	& \textcolor{red}{187.8}	& 170.7 				\\
			&		& Noggrannhet	& 93.33\%				& 93.30\%				& 93.06\%				& 93.18\%				\\
			& Test	& Tid			& 44.8				& \textcolor{blue}{43.8}	& \textcolor{red}{48.9}	& 43.6				\\
			&		& Noggrannhet	& 93.59\%				& 93.74\%				& 93.60\%				& 93.51\%				\\
	XGBoost 	&		& 			&					&					&					&					\\
			& Träning	& Tid			& \textcolor{red}{717.2}	& 263.4				& \textcolor{blue}{347.5}	& 273.3				\\
			&		& Noggrannhet	& 96.44\%				& 96.38\%				& 96.46\%				& 96.38\%				\\
			& Test	& Tid			& \textcolor{red}{56.2}	& \textcolor{blue}{31.4}	& 35.1				& 33.2				\\
			&		& Noggrannhet	& 94.70\%				& 94.95\%				& 94.66\%				& 94.94\%				\\
	Ensemble	&		& 			&					&					&					&					\\
			& Test	& Tid			& 292.3				& 189.3				& \textcolor{red}{326.3}	& \textcolor{blue}{189.1}	\\
			&		& Noggrannhet	& 97.29\%				& 97.33\%				& 97.34\%				& 97.29\%				\\
	\end{tabular}
\end{table}

\begin{table}[t]
	\centering
	\footnotesize
	\begin{tabular}{lllllll}
      \hline 
      &     precision &   recall &  f1-score &  support \\
      \hline 
           0   &    0.98  &    0.99 &     0.98    &   980 \\
           1    &   0.99  &    0.99  &    0.99     & 1135 \\
           2    &   0.97  &    0.97  &    0.97     & 1032 \\
           3    &   0.96  &    0.98    &  0.97   &   1010 \\
           4  &     0.98   &   0.97  &    0.97   &    982 \\
           5   &    0.98   &   0.97  &    0.97   &    892 \\
           6   &    0.98 &     0.98   &   0.98   &    958 \\
           7   &    0.97  &    0.96  &    0.97   &   1028 \\
           8   &    0.96   &   0.97  &    0.97   &    974 \\
           9   &   0.96   &   0.96   &   0.96   &   1009 \\
  \end{tabular}
  	\caption{\footnotesize{Klassificeringsrapport för MNIST databasen, där bilderna inte genomgått några av ytterligare behandlingarna rotation eller trunkering}}\label{classification report}\vspace{6pt}
\end{table}

I Tabell~\ref{classification report} kan vi se en typisk klassificeringsrapport för en normal bild. Därutav kan vi läsa precision, recall, f1-score och support. Precision är andelen korrekt klassificerade bilder av en viss siffra utav alla observationer som klassificerades som just den siffran, vare sig rätt eller fel. Om siffran s är den siffra vi söker efter ser formeln ut som följer \\

\noindent
asr = antalet bilder av s som vi klassificerat rätt \\
asf = antalet bilder som vi klassificerat felaktigt som s men som inte innehåller s

\[ precision = \frac{asr}{asr + asf} \]

Recall är andelen korrekt klassificerade bilder på en viss siffra delat med summan av antalet bilder som modellen har rätt om att innehålla den siffran plus antalet bilder som modellen säger helt rätt att de inte innehåller just den siffran. Om vi lägger till \\

\noindent
aisr = antalet bilder som inte innehåller s och som vi klassificerat rätt, då kan formeln för recall uttryckas som

\[ recall = \frac{asr}{asr + aisr} \]

F1-score är den harmoniska medelvärdet av precision och recall, dvs

\[f1 = 2 \times\frac{precision\times recall}{precision + recall} \]

Support är det totala antalet observationer i varje klass. 


\begin{figure}[t]
\footnotesize
    \label{Confusion matrix för all}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\linewidth]{ReportEnsembleNormalConfusion.png}
        \caption{Endast normala bilder}
        \label{confusion matrix normal}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\linewidth]{ReportEnsembleTrunkatedConfusion.png}
        \caption{Inklusive trunkerade bilder}
        \label{confusion matrix trunkerad}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\linewidth]{ReportEnsembleRotatedConfusion.png}
        \caption{Inklusive roterade bilder}
        \label{confusion matrix roterad}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\linewidth]{ReportEnsembleTrunkatedRotatedConfusion.png}
        \caption{Inklusive all formaterade bilder}
        \label{confusion matrix roterad and trunkated}
    \end{subfigure}
        \caption{\footnotesize{Confusion matrix för all de olika formateringarna. Det som utmärker sig i alla fyra matriser är i första hand likheten mellan siffrorna 2 och 7, och i andra hand 3 och 5 samt 4 och 9. Det som förefaller oväntat är att i de roterade bilderna blir sannolikheten att blanda ihop 2 och 7 i (c) blir mindre än i den första (a) samt att de olika formateringarna påverkar sannolikheten för att blanda ihop 7 och 9.}}
\end{figure}





% Add a reference for bibliography

\section{Diskussion}

Generellt fungerade modellerna nöjaktigt men i praktiken finns det alltid saker som bryter mot teorin och under påverkan från olika faktorer, från implementering till val av parametrar, plattform och dylikt.

\subsection{Val av modell}

Valet av Random Forest som en av tre modeller som användes för detta projekt och enligt Jeroen Boeye\footnote{\footnotesize{Instruktör för Datacamp-kursen Dimensionality Reduction in Python, kapitel 3, 00:05 - 00:34}} var att ''while simple in design, random forests often manage to be highly accurate and avoid overfitting even with the default Scikit-learn settings.''

\subsection{Overfitting}

När vi tittar på tabell \ref{comparison table} kan vi konstatera att speciellt RF och XGBoost visar bättre noggrannhet vid test jämfört med träning. Även för SVM är minskningen i noggrannhet i storleken ett fåtal hundradelar av en procent. Detta tyder på att våra modeller inte är övertränade på träningsdata och har låg bias.

\if(x)
% TOO LATE: change the heatmap so that it shows only bottom half of the matrix, using

\begin{table}[b]
\footnotesize
\caption{\footnotesize{???}}\label{???}
\begin{verbatim}
# Create the correlation matrix
corr = ansur_df.corr()

# Generate a mask for the upper triangle 
mask = np.triu(np.ones_like(corr, dtype=bool))

# Add the mask to the heatmap
sns.heatmap(corr, mask=mask, cmap=cmap, center=0, 
						linewidths=1, annot=True, fmt=".2f")
plt.show()
\end{verbatim}
\end{table}
\fi


\subsection{Beräkningskomplexitet}

Beräkningskomplexiteten hos ML-algoritmer kan variera baserad på olika faktorer, däribland implementeringen, storleken och komplexiteten hos data samt valet av hyperparameterar.

Komplexiteten för träning av en SVC är enligt \cite{Geron} någonstans mellan $O(r^2 \times c)$ och $O(r^3 \times c)$, där $m$ är antalet rader och $n$ är antalet kolumner i data. Av den anledningen är den modellen bättre lämpad för mindre data men i vårt fall har det ändå fungerat nöjaktigt men det kostade oss en nedskärning av antalet träningsexempel, speciellt när vi skulle jämföra de fyra modellerna gång på gång.

%The time and memory complexity of machine learning algorithms can vary based on several factors, including the specific implementation, the size and complexity of the dataset, and the hyperparameters used. Here's a general overview of how the time and memory complexity might increase with an increased number of observations for Random Forest, Support Vector Classifier (SVC), and XGBoost:

Gradient Boosting har en beräkningskomplexitet på $O(r \times c \times \log_{2}(c))$ som kan reduceras till $O(b \times c)$ med b som antalet intervall, om histogram-baserad implementering av denna model används, vilket gör modellen uppemot 100 gånger snabbare \citep{Geron}. 

För ett beslutsträd är beräkningskomplexiteten lika med $O(r \times c \times \log{c})$ \citep{Geron} och eftersom en RF modell består av många parallella beslutsträd kan komplexiteten för en sådan modell uppgå till  $O(r \times r \times c \times \log{c})$ =  $O(r^2 \times c \times \log{c})$


%Time Complexity: The time complexity of building a Random Forest model generally increases linearly with the number of observations (n) and features (p). For each decision tree in the forest, the time complexity of training a single tree is typically $O(r \times c \times \log{c})$.

\begin{table}[b]
  \centering
  \footnotesize
  \caption{\footnotesize{Sammanfattning av beräkningskomplexiteten för de tre modellerna}}\label{komplexitetssammanfattning}\vspace{6pt}
  \begin{tabular}{lll}
      \hline 
      Modell & Tid & Minne \\
      \hline 
      SVM & $O(r^2 \times c)$ - $O(r^3 \times c)$ & $O(n \times p)$ \\
      RF & $O(r^2 \times c \times \log{c})$ & $O(n \times p \times m)$ \\
      XGBoost & $O(r \times c \times \log_{2}(c))$ - $O(r \times c)$ & $O(n \times p)$ \\
      \hline 
      \end{tabular}
\end{table}

I enlighet med denna tabell är den snabbaste modellen respektive XGBoost, RF och SVC. Resultattabellen, Tabell \ref{comparison table}, säger oss dock att ordningen för träningstid är tvärtom SVC, RF och XGBoost, medan för testtid är ordningen samma som i teorin, dvs XGBoost, RF och SVC. Anledningen till den avsevärda skillnaden är inte klar men vad vi redan vet är att val av parametrar kan påverka mycket \citep{Geron}.
%Memory Complexity: Random Forests can require a significant amount of memory, especially when dealing with large datasets or a large number of trees in the forest. The memory complexity is typically $O(n \times p \times m)$, where m is the number of trees in the forest.
%Support Vector Classifier (SVC):

%Overall, Random Forest tends to have lower time complexity compared to SVC for large datasets, while XGBoost can be more memory-efficient and faster to train compared to both Random Forest and SVC in many cases, especially for large datasets. However, the actual performance may vary depending on the specific characteristics of the dataset and the hyperparameters used for each algorithm.

\section{Slutsats}

I denna rapport gick vi igenom de steg man behöver ta för att träna en modell och sedan använda det till att klassificera bilder från MNIST databasen över handskrivna siffror. I detta arbete kunde testbilder klassificeras med en noggrannhet över 97 procent. Det finns bättre algoritmer som är ännu mer träffsäkra varav Convolutional Neural Networks (CNN) och deep learning är de mest kända. Men för de klassiska modellerna som vi använde här är resultatet ändå mycket bra.

\subsection{Framtida arbeten}

En sak som skulle kunna förbättra resultatet genom att minska träningstiden är just motsvarande vad vi redan har gjort i vår jämförelse mellan olika förbehandlingar, nämligen trunkering av bilderna. Ytterligare en sak skulle vi kunna göra och det är att titta på statistiken för varje pixel och se hur mycket de varierar. En pixel vars värde inte varierar mycket mellan olika siffror spelar en mindre roll för att urskilja de olika siffrorna och därmed kan det elimineras från mängden pixlar som ingår i träningen. Detta minskar träningstiden och kan därför förbättra träningen då man kan använda sig av fler träningsbilder.

I början var koden olika för olika modeller. Men det tog ett bra tag innan koderna blev enhetliga, vilket med tanke på tidsbrist inte kunde organiseras på rätt sätt. Det goda resultatet har inte påverkats men det kunde organiseras bättre i form av funktioner som kunde förenkla de omskrivningar som har gjorts för varje modeller. Detta är en del av det pågående och framtida arbetet.

Vi skulle kunna använda SGDClassifier för en bättre implementering av SVC, som motsvarar linjär SVC med tidskomplexiteten $O(m \times n)$. Detta är något att tänka på vid en nästa version.

\subsubsection{Explained Variance Ratio}

För varje egenvektor som spänner det transformerade koordinatsystemet för den originella rymden som är spänd av datasetets vektorer, finns ett motsvarande egenvärde. Man definierar Exaplained Variance Ratio (EVR) \citep{Izenman,Kuhn,open} eller Variance Explained Ratio (VER) \citep{Raschka} för varje egenvektor som dess motsvarande egenvärde delat med summan av samtliga egenvärdena för alla egenvektorer som spänner upp det transformerade systemet. Det vill säga att i matematiska termer, om $\lambda_i$ representerar det egenvärde som motsvarar egenvektor nummer $i$ i principal komponenten och $\lambda_1, \lambda_2, ..., \lambda_n$ är  egenvektorerna sorterade i fallande ordning, ges EVR för $i$-te principalkomponenten av

\[ EVR_i = \frac{\lambda_i}{\Sigma_{j=1}^{n}\lambda_j}\]

Enklare sagt, EVR visar hur mycket information eller varians reflekteras i den lägre dimensionerade rymden som spänns av principalkomponenterna. Detta ger en förstahands information om varje individuell komponent. Koden som används för att utnyttja EVR är som framgår av tabell \ref{evr code}.

\begin{table}[t]
	\footnotesize
	\caption{\footnotesize{Kod som redan finns i sklearn och kan användas för beräkning av Explained Veriance Ratio (EVR)}}\label{evr code}
\begin{verbatim}
from sklearn.decomposition import PCA
pca = PCA()
pca.fit(std_df)
print(pca.explained_variance_ratio_)
\end{verbatim}
\end{table}

Det är klart att vi använder mer eller mindre samma princip när vi utnyttjar cross validation eller grid search men dels tar detta betydligt mindre tid att genomföra/ beräkna och dels blir det lättare för oss att ha kontroll över vilka komponenter som används och i vilken utsträckning dessa påverkar variansen i modellen. Detta skulle vi kunna använda till exempel för att se vilka komponenter som är inblandade i igenkänningen av varje siffra. Huruvida detta skulle kunna generera bättre resultat kan undersökas i en framtida version.

%\setcitestyle{round}
\bibliographystyle{apalike}
\bibliography{references}

\end{document}